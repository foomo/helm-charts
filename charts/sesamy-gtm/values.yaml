# -- Overrides the chart's name
nameOverride: ""
# -- Overrides the chart's computed fullname
fullnameOverride: ""
# -- The name of the Namespace to deploy
# If not set, `.Release.Namespace` is used
namespaceOverride: ''

# -- Number of revisions to retain to allow rollback
revisionHistoryLimit: 10

# Google Tag Manager configuration
gtm:
  image:
    # -- The image repository
    repository: gcr.io/cloud-tagging-10302018/gtm-cloud-image
    # -- The image pull policy
    pullPolicy: IfNotPresent
    # -- The image tag
    tag: "2.2.0"
  # -- Base64-encoded container parameters in the URL query string format.
  containerConfig: ''
  # -- Interval between container refreshes.
  containerRefreshSeconds: 60
  # -- (Optional) Base64-encoded service account credential that is authorized to access resources.
  # To use the BigQuery or Firestore API outside of Google Cloud.
  googleApplicationCredentials: ''
  # -- (Optional) Google Cloud project ID.
  # Let the tagging server implicitly choose the project.
  googleCloudProject: ''

# Google Tag Manger TLS Reverse Proxy configurations
# All urls have to be valid https urls, so proxy https traffic to your containers.
# Create a self-signed certificate by running
# $ openssl req -x509 -newkey rsa:2048 -keyout tls.key -out tls.crt -nodes -subj '/CN=sesamy'
proxy:
  # TLS configuration
  tls:
    # -- Base64 encoded TLS key
    key: ""
    # -- Base64 encoded TLS cert
    crt: ""
  # Docker image
  image:
    # -- The image repository
    repository: 'nginx'
    # -- The image pull policy
    pullPolicy: IfNotPresent
    # -- The image tag
    tag: '1.25-alpine'
  # -- Resource request & limits.
  resources: {}
  # -- Nginx SSL Reverse Proxy config.
  # The value is templated using `tpl`.
  # @default -- see values.yaml
  config: |
    server {
      listen              443 ssl;

      ssl_certificate     /etc/nginx/ssl/tls.crt;
      ssl_certificate_key /etc/nginx/ssl/tls.key;
      ssl_session_cache   shared:SSL:10m;
      ssl_session_timeout 1h;
      ssl_buffer_size     8k;

      location / {
          proxy_pass         http://0.0.0.0:{{ .Values.tagging.service.port }};
          proxy_set_header   Host $host;
          proxy_set_header   X-Real-IP $remote_addr;
          proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;
          proxy_set_header   X-Forwarded-Host $server_name;
          proxy_set_header   Upgrade $http_upgrade;
          proxy_set_header   Connection 'upgrade';
          proxy_cache_bypass $http_upgrade;
      }
    }

# GTM Tagging configuration
tagging:
  # -- Number of replicas
  replicaCount: 1
  # -- Pod Disruption Budget maxUnavailable
  maxUnavailable: null
  # -- Host aliases to add
  hostAliases: []
  #  - ip: 1.2.3.4
  #    hostnames:
  #      - domain.tld
  # -- Image pull secrets
  imagePullSecrets: []
  # -- Annotations for pods
  podAnnotations: {}
  # -- Labels for pods
  podLabels: {}
  # -- The SecurityContext for pods
  podSecurityContext: {}
  #  fsGroup: 2000
  securityContext: {}
  #  capabilities:
  #    drop:
  #      - ALL
  #  readOnlyRootFilesystem: true
  #  runAsNonRoot: true
  #  runAsUser: 1000
  service:
    # -- Port of the service
    port: 8080
    # -- Type of the service
    type: ClusterIP
    # -- Annotations for the service
    annotations: {}
    # -- ClusterIP of the gateway service
    clusterIP: null
    # -- Node port if service type is NodePort
    nodePort: null
    # -- Set appProtocol for the service
    appProtocol: null
    # -- Labels for service
    labels: {}
  # -- Resource request & limits.
  resources: {}
  #  requests:
  #    cpu: 100m
  #    memory: 128Mi
  #  limits:
  #    cpu: 100m
  #    memory: 128Mi
  # @default -- Liveness probe settings for pods.
  livenessProbe:
    httpGet:
      path: /healthz
      port: http
  # @default -- Readiness probe settings for pods.
  readinessProbe:
    httpGet:
      path: /healthz
      port: http
  autoscaling:
    # -- Enable autoscaling
    enabled: false
    # -- Minimum autoscaling replicas
    minReplicas: 1
    # -- Maximum autoscaling replicas
    maxReplicas: 100
    # -- Target CPU utilisation percentage
    targetCPUUtilizationPercentage: 80
    # -- Target memory utilisation percentage
    targetMemoryUtilizationPercentage: null
    # -- Custom metrics using the HPA/v2 schema (for example, Pods, Object or External metrics)
    customMetrics: []
    #  - type: Pods
    #    pods:
    #      metric:
    #        name: loki_lines_total
    #      target:
    #        type: AverageValue
    #        averageValue: 10k
    behavior:
      # -- Enable autoscaling behaviours
      enabled: false
      # -- Scale down policies, must conform to HPAScalingRules
      scaleDown: {}
      # -- Scale up policies, must conform to HPAScalingRules
      scaleUp: {}
  # -- Environment variables to add
  extraEnv: []
  # -- Environment variables from secrets or configmaps to add
  extraEnvFrom: []
  # -- Volume mounts to add
  extraVolumeMounts: []
  #  - name: foo
  #    mountPath: "/etc/foo"
  #    readOnly: true
  # -- Volumes to add
  extraVolumes: []
  #  - name: foo
  #    secret:
  #      secretName: mysecret
  #      optional: false
  # -- Tolerations settings for pods.
  nodeSelector: {}
  # -- Tolerations settings for pods.
  tolerations: []
  # -- Affinity settings for pods.
  affinity: {}
  # -- DNSConfig settings for pods.
  dnsConfig: {}

# GTM Preview configuration
preview:
  # -- Number of replicas
  replicaCount: 1
  # -- Pod Disruption Budget maxUnavailable
  maxUnavailable: null
  # -- Host aliases to add
  hostAliases: []
  #  - ip: 1.2.3.4
  #    hostnames:
  #      - domain.tld
  # -- Image pull secrets
  imagePullSecrets: []
  # -- Annotations for pods
  podAnnotations: {}
  # -- Labels for pods
  podLabels: {}
  # -- The SecurityContext for pods
  podSecurityContext: {}
  #  fsGroup: 2000
  securityContext: {}
  #  capabilities:
  #    drop:
  #      - ALL
  #  readOnlyRootFilesystem: true
  #  runAsNonRoot: true
  #  runAsUser: 1000
  service:
    # -- Port of the service
    port: 8080
    # -- Type of the service
    type: ClusterIP
    # -- Annotations for the service
    annotations: {}
    # -- Labels for service
    labels: {}
  # -- Resource request & limits.
  resources: {}
  #  requests:
  #    cpu: 100m
  #    memory: 128Mi
  #  limits:
  #    cpu: 100m
  #    memory: 128Mi
  # @default -- Liveness probe settings for pods.
  livenessProbe:
    httpGet:
      path: /healthz
      port: http
  # @default -- Readiness probe settings for pods.
  readinessProbe:
    httpGet:
      path: /healthz
      port: http
  autoscaling:
    # -- Enable autoscaling
    enabled: false
    # -- Minimum autoscaling replicas
    minReplicas: 1
    # -- Maximum autoscaling replicas
    maxReplicas: 100
    # -- Target CPU utilisation percentage
    targetCPUUtilizationPercentage: 80
    # -- Target memory utilisation percentage
    targetMemoryUtilizationPercentage: null
    # -- Custom metrics using the HPA/v2 schema (for example, Pods, Object or External metrics)
    customMetrics: []
    #  - type: Pods
    #    pods:
    #      metric:
    #        name: loki_lines_total
    #      target:
    #        type: AverageValue
    #        averageValue: 10k
    behavior:
      # -- Enable autoscaling behaviours
      enabled: false
      # -- Scale down policies, must conform to HPAScalingRules
      scaleDown: {}
      # -- Scale up policies, must conform to HPAScalingRules
      scaleUp: {}
  # -- Environment variables to add
  extraEnv: []
  # -- Environment variables from secrets or configmaps to add
  extraEnvFrom: []
  # -- Volume mounts to add
  extraVolumeMounts: []
  #  - name: foo
  #    mountPath: "/etc/foo"
  #    readOnly: true
  # -- Volumes to add
  extraVolumes: []
  #  - name: foo
  #    secret:
  #      secretName: mysecret
  #      optional: false
  # -- Tolerations settings for pods.
  nodeSelector: {}
  # -- Tolerations settings for pods.
  tolerations: []
  # -- Affinity settings for pods.
  affinity: {}
  # -- DNSConfig settings for pods.
  dnsConfig: {}

# Ingress configuration
ingress:
  enabled: false
  className: ""
  annotations: {}
  paths:
    preview:
      - path: /gtm
        pathType: Prefix
        port: 8080
    tagging:
      - path: /g/collect
        pathType: Prefix
        port: 8080
      - path: /gtm.js
        pathType: Exact
        port: 8080
      - path: /gtag/js
        pathType: Prefix
        port: 8080
  hosts:
    - example.com
  tls: []
  #  - secretName: example-com-tls
  #    hosts:
  #      - example.com

# ServiceAccount configuration
serviceAccount:
  # -- Specifies whether a service account should be created
  create: true
  # -- Automatically mount a ServiceAccount's API credentials?
  automount: true
  # -- Annotations to add to the service account
  annotations: {}
  # -- The name of the service account to use.
  # -- If not set and create is true, a name is generated using the fullname template
  name: ""

# ServiceMonitor configuration
serviceMonitor:
  # -- If enabled, ServiceMonitor resources for Prometheus Operator are created
  enabled: false
  # -- Alternative namespace for ServiceMonitor resources
  namespace: null
  # -- Namespace selector for ServiceMonitor resources
  namespaceSelector: {}
  # -- Optional expressions to match on
  matchExpressions: []
  #  - key: prometheus.io/service-monitor
  #    operator: NotIn
  #    values:
  #      - "false"
  # -- ServiceMonitor annotations
  annotations: {}
  # -- Additional ServiceMonitor labels
  labels: {}
  # -- ServiceMonitor scrape interval
  interval: null
  # -- ServiceMonitor scrape timeout in Go duration format (e.g. 15s)
  scrapeTimeout: null
  # -- ServiceMonitor relabel configs to apply to samples before scraping
  # https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#relabelconfig
  relabelings: []
  # -- ServiceMonitor metric relabel configs to apply to samples before ingestion
  # https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#endpoint
  metricRelabelings: []
  ##ServiceMonitor will add labels from the service to the Prometheus metric
  # https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#servicemonitorspec
  targetLabels: []
  # -- ServiceMonitor will use http by default, but you can pick https as well
  scheme: http
  # -- ServiceMonitor will use these tlsConfig settings to make the health check requests
  tlsConfig: null

# NetworkPolicy configuration
networkPolicy:
  # -- Specifies whether Network Policies should be created
  enabled: false
  metrics:
    # -- Specifies the Pods which are allowed to access the metrics port.
    # As this is cross-namespace communication, you also need the namespaceSelector.
    podSelector: {}
    # -- Specifies the namespaces which are allowed to access the metrics port
    namespaceSelector: {}
    # -- Specifies specific network CIDRs which are allowed to access the metrics port.
    # In case you use namespaceSelector, you also have to specify your kubelet networks here.
    # The metrics ports are also used for probes.
    cidrs: []
  ingress:
    # -- Specifies the Pods which are allowed to access the http port.
    # As this is cross-namespace communication, you also need the namespaceSelector.
    podSelector: {}
    # -- Specifies the namespaces which are allowed to access the http port
    namespaceSelector: {}
  externalStorage:
    # -- Specify the port used for external storage, e.g. AWS S3
    ports: []
    # -- Specifies specific network CIDRs you want to limit access to
    cidrs: []
  discovery:
    # -- Specify the port used for discovery
    port: null
    # -- Specifies the Pods labels used for discovery.
    # As this is cross-namespace communication, you also need the namespaceSelector.
    podSelector: {}
    # -- Specifies the namespace the discovery Pods are running in
    namespaceSelector: {}

# RBAC configuration
rbac:
  # -- Create PodSecurityPolicy.
  enabled: false
